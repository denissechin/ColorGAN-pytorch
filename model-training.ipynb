{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import loss_holder, print_image, print_train_image, print_test_image\n",
    "from modeling import ResNetUNetGenerator, Discriminator\n",
    "from dataset import Gray_colored_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_to_input_image = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(256),\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_to_target_image = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(256),\n",
    "            transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "dataset_path = '../input/flickr30k/images'\n",
    "dataset = Gray_colored_dataset(dataset_path, transform_to_target_image, transform_to_input_image)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "inputs, labels = next(iter(dataloader))\n",
    "print('Input Image')\n",
    "print_image(inputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Generator and Discriminator\n",
    "***\n",
    "Generator is basically a Unet with some tweaks\n",
    "\n",
    "Discriminator is a typical conv classifier, adjustable for any input image size\n",
    "\n",
    "We will train the model with:\n",
    "- BCELoss from scores of Discriminator\n",
    "- Mean of MAE and RMSE from comparison of generated image and ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = 16\n",
    "beta1 = 0.5\n",
    "\n",
    "netG = ResNetUNet().to(device)\n",
    "netD = Discriminator(256).to(device)\n",
    "\n",
    "criterion = nn.BCELoss().to(device)\n",
    "MSE_loss = nn.MSELoss().to(device)\n",
    "\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "lr = 0.0001\n",
    "num_epochs = 15\n",
    "\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training process\n",
    "***\n",
    "Training of this GAN is pretty simple\n",
    "1. Firstly, we update Discriminator's gradients with ground truth image and its error\n",
    "2. Secondly, we generate a colored image and accumulate Discriminator's gradients with processed colored image and its error and update Discriminator's weights\n",
    "3. Then we calculate all the losses' values for Generator and update it's weights\n",
    "\n",
    "Also we freeze resnet layers of Generator for 1/3 of first epoch in order not to wreck well-pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Training Loop...\")\n",
    "netG.train()\n",
    "netD.train()\n",
    "\n",
    "netG.freeze_parameters()\n",
    "\n",
    "losses_holder = loss_holder()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "            \n",
    "        if netG.frozen and i > len(dataloader)//3:\n",
    "            netG.unfreeze_parameters()\n",
    "                \n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        b_size = inputs.shape[0]\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(labels).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        fake = netG(inputs)\n",
    "        label.fill_(fake_label)\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "        \n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        Adv_loss = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        RMSE_err = torch.sqrt(MSE_loss(fake, labels))\n",
    "        perc_loss = Adv_loss * 1e-2 + RMSE_err\n",
    "        perc_loss.backward()\n",
    "        losses_holder.add_batch_(errD_real.item(), errD_fake.item(), perc_loss.item(), Adv_loss.item())\n",
    "        \n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "        \n",
    "        # Output training stats     \n",
    "        if i % (len(dataloader)//10) == 0:\n",
    "            current_error_means = losses_holder.get_means()\n",
    "            print('[%d/%d][%d%%]\\tLoss_D_real: %.4f\\tLoss_D_fake: %.4f\\tLoss_G: %.4f\\tAdversarial loss: %.4f\\t'\n",
    "                  % (epoch, num_epochs, (i * 100 / len(dataloader)),\n",
    "                     current_error_means['D_real_loss'], current_error_means['D_fake_loss'], \n",
    "                     current_error_means['G_loss'], current_error_means['Adv_loss']))\n",
    "            losses_holder.clear_values_()\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check on train data perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lab = next(iter(dataloader))\n",
    "\n",
    "print_train_image(netG, inp[0], lab[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check on old photos perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_test_dataset = ImageFolder('../input/test-images', transform=transform_to_input_image)\n",
    "print_images_from_dataset(netG, gray_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save models and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': netG.state_dict(),\n",
    "            'optimizer_state_dict': optimizerG.state_dict(),\n",
    "            }, './generator.pth')\n",
    "torch.save({\n",
    "            'model_state_dict': netD.state_dict(),\n",
    "            'optimizer_state_dict': optimizerD.state_dict(),\n",
    "            }, './discriminator.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
